{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQSdcaXKRGe24ygnmeApBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0cad7ca82994d2c931eaf0a83ee2e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e6718b2b1574117befa7ae0dfe93bfe",
              "IPY_MODEL_5853cafffa9b4814a6747dccfc159b10",
              "IPY_MODEL_8ce431b2d0414ce689a8669352a40241"
            ],
            "layout": "IPY_MODEL_a2b3e7c656cc4406acefedc1f193479e"
          }
        },
        "4e6718b2b1574117befa7ae0dfe93bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a9d1f78d42f45e0b1c53a800cf8b6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_e38833c1edd949f2ac3c75a22aec5a4d",
            "value": "Batches: 100%"
          }
        },
        "5853cafffa9b4814a6747dccfc159b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_addb6e662ef64065ba29e8cab9ac42d8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39be0f8fc4f5499f8a21c2e24e89ab65",
            "value": 1
          }
        },
        "8ce431b2d0414ce689a8669352a40241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cc6f688a8ab4c6dbf5dbc4f34a1446c",
            "placeholder": "​",
            "style": "IPY_MODEL_0930257f62ac42779ac2a6ce4724eb62",
            "value": " 1/1 [00:06&lt;00:00,  6.15s/it]"
          }
        },
        "a2b3e7c656cc4406acefedc1f193479e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9d1f78d42f45e0b1c53a800cf8b6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38833c1edd949f2ac3c75a22aec5a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "addb6e662ef64065ba29e8cab9ac42d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39be0f8fc4f5499f8a21c2e24e89ab65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cc6f688a8ab4c6dbf5dbc4f34a1446c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0930257f62ac42779ac2a6ce4724eb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarunagarwal1981/meassist/blob/main/meassistnew.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3N1tjBKp7fi"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers faiss-gpu sentence-transformers pdfminer.six python-docx openpyxl langchain\n",
        "\n",
        "# Depending on your specific needs, you might need to install additional packages or specific versions of these packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic imports for data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Library imports for file handling\n",
        "from pdfminer.high_level import extract_text\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "\n",
        "# Imports for embeddings and FAISS\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# Additional utility libraries\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# LangChain or other specific libraries can be imported based on your usage\n",
        "# import langchain  # Uncomment or modify based on your project's requirements\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OhbzdY9zrENK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folder_path = '/content/drive/My Drive/LLM'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH10rHevvrPd",
        "outputId": "b1850b25-51aa-4af0-cc7f-81e25f545c8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "from docx import Document\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    try:\n",
        "        text = extract_text(pdf_path)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    \"\"\"Extracts text from a DOCX file.\"\"\"\n",
        "    try:\n",
        "        doc = Document(docx_path)\n",
        "        fullText = [paragraph.text for paragraph in doc.paragraphs]\n",
        "        return '\\n'.join(fullText)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {docx_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_excel(excel_path):\n",
        "    \"\"\"Extracts text from an Excel file, concatenating all text from the workbook.\"\"\"\n",
        "    try:\n",
        "        df = pd.concat(pd.read_excel(excel_path, sheet_name=None), ignore_index=True)\n",
        "        text = df.to_csv(index=False, header=False)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {excel_path}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "PMKNsMrpqDKR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files_in_folder(folder_path):\n",
        "    document_texts = []  # Initialize a list to hold document texts\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.endswith('.pdf'):\n",
        "                text = extract_text_from_pdf(file_path)\n",
        "            elif file.endswith('.docx'):\n",
        "                text = extract_text_from_docx(file_path)\n",
        "            elif file.endswith(('.xls', '.xlsx')):\n",
        "                text = extract_text_from_excel(file_path)\n",
        "            else:\n",
        "                text = None\n",
        "\n",
        "            if text:\n",
        "                document_texts.append(text)  # Store the extracted text\n",
        "    return document_texts\n",
        "\n",
        "\n",
        "# Replace 'folder_path' with your folder's path\n",
        "folder_path = '/content/drive/My Drive/LLM'  # Adjust this path\n",
        "process_files_in_folder(folder_path)\n"
      ],
      "metadata": {
        "id": "p29PIA6jwbFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize a pre-trained model for embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def generate_embeddings(text_list):\n",
        "    \"\"\"Generates embeddings for a list of text documents.\"\"\"\n",
        "    embeddings = model.encode(text_list, show_progress_bar=True)\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "kPnxjOizw9hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    \"\"\"Creates a FAISS index for a set of document embeddings.\"\"\"\n",
        "    dimension = embeddings.shape[1]  # Get the dimension of embeddings\n",
        "    index = faiss.IndexFlatL2(dimension)  # Use the FlatL2 index for Euclidean distance\n",
        "    index.add(embeddings)  # Add embeddings to the index\n",
        "    return index\n",
        "\n",
        "# Example usage:\n",
        "# Assume `document_embeddings` is your array of document embeddings from the previous step\n",
        "# document_embeddings = generate_embeddings(your_document_texts)\n",
        "# faiss_index = create_faiss_index(np.array(document_embeddings))\n"
      ],
      "metadata": {
        "id": "NoaxO195xEhZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_documents(query, index, text_list, top_k=5):\n",
        "    \"\"\"Searches the index for the documents most similar to the query.\"\"\"\n",
        "    query_embedding = model.encode([query])[0]  # Convert query to embedding\n",
        "    distances, indices = index.search(np.array([query_embedding]), top_k)  # Find the top_k closest embeddings\n",
        "\n",
        "    results = [(text_list[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "# results = search_documents(\"Your query here\", faiss_index, your_document_texts)\n",
        "# for text, score in results:\n",
        "#     print(f\"Score: {score:.2f}, Text: {text[:200]}...\")  # Print the beginning of each matching document\n"
      ],
      "metadata": {
        "id": "cA87DBp6xLK2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "rcZuIZmcAw7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Ensure your API key is set correctly\n",
        "openai.api_key = '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'\n",
        "\n",
        "def generate_response_with_gpt(augmented_prompt):\n",
        "    \"\"\"\n",
        "    Generates a response using the OpenAI ChatCompletion API for chat models.\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": augmented_prompt}\n",
        "        ]\n",
        "    )\n",
        "    # Extracting the text response from the list of messages\n",
        "    # The response structure might need adjustment based on the actual output\n",
        "    return response.choices[0].message['content']\n",
        "\n"
      ],
      "metadata": {
        "id": "5W_SI1CuAMH2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_augmented_prompt(query, retrieved_documents, top_k=3):\n",
        "    \"\"\"Creates an augmented prompt by combining the query with top retrieved documents.\"\"\"\n",
        "    # Sort retrieved documents by their score (assuming the second tuple element is the score)\n",
        "    retrieved_documents = sorted(retrieved_documents, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select the top_k documents and concatenate their text\n",
        "    context = \" \".join([doc[0] for doc in retrieved_documents[:top_k]])\n",
        "\n",
        "    # Combine the original query with the context\n",
        "    augmented_prompt = f\"Based on the following information: {context} \\n\\nAnswer the question: {query}\"\n",
        "    return augmented_prompt\n"
      ],
      "metadata": {
        "id": "B4YLlQDpz3jK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_query(query):\n",
        "    \"\"\"Handles a user query by retrieving relevant documents and generating a response.\"\"\"\n",
        "    # Step 1: Retrieve relevant documents\n",
        "    retrieved_docs = search_documents(query, faiss_index, your_document_texts)\n",
        "\n",
        "    # Step 2: Create an augmented prompt with the query and retrieved documents\n",
        "    augmented_prompt = create_augmented_prompt(query, retrieved_docs)\n",
        "\n",
        "    # Step 3: Generate a response using GPT with the augmented prompt\n",
        "    response = generate_response_with_gpt(augmented_prompt)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage:\n",
        "# response = handle_query(\"What are the main benefits of product X?\")\n",
        "# print(response)\n"
      ],
      "metadata": {
        "id": "qPJexsFu0CNZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'folder_path' with your folder's path\n",
        "folder_path = '/content/drive/My Drive/LLM'  # Adjust this path\n",
        "your_document_texts = process_files_in_folder(folder_path)  # Process documents and collect texts\n",
        "\n",
        "# Generate embeddings for these texts\n",
        "document_embeddings = generate_embeddings(your_document_texts)\n",
        "\n",
        "# Create a FAISS index with these embeddings\n",
        "# First, ensure embeddings is a NumPy array for FAISS\n",
        "document_embeddings_np = np.asarray(document_embeddings)\n",
        "faiss_index = create_faiss_index(document_embeddings_np)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e0cad7ca82994d2c931eaf0a83ee2e86",
            "4e6718b2b1574117befa7ae0dfe93bfe",
            "5853cafffa9b4814a6747dccfc159b10",
            "8ce431b2d0414ce689a8669352a40241",
            "a2b3e7c656cc4406acefedc1f193479e",
            "1a9d1f78d42f45e0b1c53a800cf8b6ec",
            "e38833c1edd949f2ac3c75a22aec5a4d",
            "addb6e662ef64065ba29e8cab9ac42d8",
            "39be0f8fc4f5499f8a21c2e24e89ab65",
            "1cc6f688a8ab4c6dbf5dbc4f34a1446c",
            "0930257f62ac42779ac2a6ce4724eb62"
          ]
        },
        "id": "uT4PgJHW4IMK",
        "outputId": "ce4c6c97-5910-4aae-d468-a03131b9087d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0cad7ca82994d2c931eaf0a83ee2e86"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to define or import all the necessary functions and initialize APIs and models before this snippet.\n",
        "\n",
        "def main():\n",
        "    print(\"Please enter your question or 'exit' to quit:\")\n",
        "    while True:\n",
        "        query = input(\"Your question: \")\n",
        "        if query.lower() == 'exit':\n",
        "            print(\"Exiting the program. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Retrieve relevant documents for the query\n",
        "        retrieved_docs = search_documents(query, faiss_index, your_document_texts)\n",
        "\n",
        "        if not retrieved_docs:\n",
        "            print(\"Sorry, no relevant information could be found for your question.\")\n",
        "            continue\n",
        "\n",
        "        # Create an augmented prompt combining the query with the retrieved documents\n",
        "        augmented_prompt = create_augmented_prompt(query, retrieved_docs)\n",
        "\n",
        "        # Generate a response using GPT based on the augmented prompt\n",
        "        response = generate_response_with_gpt(augmented_prompt)\n",
        "\n",
        "        print(\"Answer:\", response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWCXytin0WGk",
        "outputId": "1940dcc1-5a23-4e9a-d5c2-7335dfd586c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your question or 'exit' to quit:\n",
            "Your question: pi, pmax is low while pcomp is normal. help me troubleshoot\n",
            "Answer: When facing a situation where Pi and Pmax are low while Pcomp is normal, it can indicate several potential issues. Here are some troubleshooting steps that can help identify the cause:\n",
            "\n",
            "1. **Fuel System Issues**:\n",
            "   - Check for any fuel-related problems such as clogged fuel filters, incorrect fuel pressure, or air in the fuel system.\n",
            "   - Verify that the fuel injection system is operating correctly and delivering the right amount of fuel to the cylinders.\n",
            "   - Inspect the fuel quality and ensure it meets the engine requirements.\n",
            "\n",
            "2. **Governor Problems**:\n",
            "   - Check the governor for any malfunctions that may be causing incorrect adjustments to Pi and Pmax.\n",
            "   - Ensure that the governor is responding appropriately to load changes and maintaining the desired engine parameters.\n",
            "\n",
            "3. **Mechanical Component Checks**:\n",
            "   - Inspect the engine components related to Pi and Pmax adjustments, such as the fuel pump, injection nozzles, and timing mechanisms.\n",
            "   - Check for any mechanical issues within the cylinders that could be affecting combustion pressures.\n",
            "\n",
            "4. **Exhaust System and Turbocharger**:\n",
            "   - Verify that the exhaust system is functioning properly and that there are no obstructions or leaks that could affect engine performance.\n",
            "   - Inspect the turbocharger for any issues that may be impacting engine operation.\n",
            "\n",
            "5. **System Calibration**:\n",
            "   - Ensure that the engine control system is calibrated correctly and that all sensors are providing accurate data for Pi, Pmax, and Pcomp adjustments.\n",
            "   - Check the settings and configurations of the engine control system to ensure proper operation.\n",
            "\n",
            "6. **Consult Manufacturer Manuals**:\n",
            "   - Refer to the engine manufacturer's manual and troubleshooting guides for specific guidance on addressing issues related to Pi, Pmax, and Pcomp discrepancies.\n",
            "\n",
            "By following these troubleshooting steps and systematically checking each potential cause, you can pinpoint the issue causing low Pi and Pmax while Pcomp remains normal. If the problem persists or is unclear, it may be necessary to consult with experienced engineers or contact technical support for further assistance.\n",
            "Your question: give me the guidelines for cylinder oil usage in man engines. also provide me the source of your answer.\n",
            "Answer: The guidelines for cylinder oil usage in MAN engines, particularly when operating on low-sulphur fuels, are provided in the service letters SL2021-714/PXN, SL2023-738/IKCA, and SL2019-671/JAP from MAN Energy Solutions. These letters detail recommendations for cylinder oil selection, feed rate adjustments, monitoring cylinder condition, controlling deposits, and ensuring optimal engine performance while operating on fuels with varying sulphur content.\n",
            "\n",
            "For detailed and specific information on cylinder oil guidelines for MAN engines, including recommended BN levels, actions to take in case of deposits, monitoring parameters, and operational considerations, please refer to the corresponding service letters mentioned above.\n",
            "Your question: can you give me detailed answer to my previous question\n",
            "Answer: Based on the detailed information provided, it seems like your previous question is related to the procedures and guidelines outlined in the Service Letter SL2020-692/KAMO regarding the LDCL cooling system for MAN B&W two-stroke marine diesel engines operating on very-low-sulphur fuels.\n",
            "\n",
            "Here is a detailed explanation based on the content of the Service Letter:\n",
            "\n",
            "1. **LDCL System Deactivation:** The Service Letter specifies that when using very-low-sulphur fuels with up to 0.50% sulphur, the LDCL cooling system can be deactivated for certain engine types.\n",
            "\n",
            "2. **Updates for LDCL Cooling System:** The Service Letter describes different actions based on the engine dot number and ECS version. It explains the procedure for deactivating the LDCL system, conducting temperature adjustments, and maintaining mechanical parts when using low-sulphur fuels.\n",
            "\n",
            "3. **Parameter Updates and ECS Software:** Depending on the engine dot number and ECS version, a parameter update package or ECS update may be available for optimizing the LDCL system.\n",
            "\n",
            "4. **Continuous Auto Tuning:** The letter also provides details about Auto Tuning functionality with clear instructions on Cylinder Pressure Balancing, Cylinder Pressure Mean Value Adjustment, and Continuous Adjustment of Cylinder Pressure Mean Values.\n",
            "\n",
            "5. **Operating Guidelines:** The letter gives recommendations on temperature adjustments, mechanical part maintenance, and provides step-by-step guides on using the Auto Tuning functionality for cylinder pressure balancing and mean value adjustment.\n",
            "\n",
            "In conclusion, the Service Letter SL2020-692/KAMO offers comprehensive instructions and guidelines on how to operate the LDCL cooling system on MAN B&W two-stroke marine diesel engines when using very-low-sulphur fuels. It includes procedures for deactivating the LDCL system, making temperature adjustments, maintaining mechanical parts, and utilizing the Auto Tuning functionality for pressure adjustments.\n",
            "Your question: exit\n",
            "Exiting the program. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}